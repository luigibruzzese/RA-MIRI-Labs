UPC - Randomized Algorithms course - A.Y. 2024/2025

## Assignment #3: cardinality estimation

This repository contains all the materials delivered for the third assignment in the scope of the Randomized Algorithms course at UPC.
In particular:
- [luigi.bruzzese-cardest.pdf](https://github.com/luigibruzzese/RA-MIRI-Labs/blob/main/Assignment-3/luigi.bruzzese-cardest.pdf) is a report that explains the whole process for fulfilling the assignment;
- [assignment3.py](https://github.com/luigibruzzese/UPC-RA-MIRI-Lab/blob/main/Assignment-3/assignment3.py) is the script used to show the results explained in the report.
  The script can be run from a terminal with the following instruction:
    assignment3.py [-h] --data DATA --alg {HLL,REC,LL,AS} [--T T] [--param PARAM]
  where:
  - --data=string: sets the relative path of the file to be used as the data stream. The file should contain one entry for each line.
  - --alg={HLL,REC,LL,AS}: sets the algorithm to be used, among HLL (HyperLogLog), REC (Recordinality), LL (LogLog) and AS (Adaptive Sampling);
  - --T=positive integer: sets the number of times the algorithm is run for the prediction, each time with a different hash function. The default value is 1000;
  - --param=positive integer: sets the parameter m for HLL or LL, k for REC, maxS for AS. The default value is 256;
- [auto.py](https://github.com/luigibruzzese/UPC-RA-MIRI-Lab/blob/main/Assignment-3/auto.py) is a script that can be run to automatically execute all the combinations of algorithm and parameter analyzed in the report. The results are outputted in datasets/output.
- [experiment.py](https://github.com/luigibruzzese/UPC-RA-MIRI-Lab/blob/main/Assignment-3/experiment.py) is the script used for an experimental algorithm analyzed in the report, which follows a similar behavior of HLL and LL but with a different shape of the final estimation.
  It can be run from a terminal with the following instruction:
  experiment.py [-h] --data DATA [--T T] [--m M] [--model {1,2,3}] [--realCardinality REALCARDINALITY]
  where:
    --data=string: sets the relative path of the file to be used as the data stream. The file should contain one entry for each line.
    --T=positive integer: sets the number of times the algorithm is run for the prediction, each time with a different hash function. The default value is 1000;
    --m=m: sets the parameter m to be used for the algorithm. The default value is 256;
    --model={1,2,3}: sets the model to be used for estimating delta.
    --realCardinality=positive integer: if set, instead of estimating the cardinality for the dataset provided using the defined model, the real cardinality is used to estimate delta; in that case, the parameter model is not considered, and the output will be the value of delta estimated.
- [zipf](https://github.com/luigibruzzese/UPC-RA-MIRI-Lab/blob/main/Assignment-3/zipf) is the folder that contains:
  - [generateSyntheticDS.py](https://github.com/luigibruzzese/UPC-RA-MIRI-Lab/blob/main/Assignment-3/zipf/generateSyntheticDS.py) is the script used for generating the corresponding .txt files (present in the same folder) with words stream that follow the Zipf law.
    It can be run from a terminal with the following instructions:
    generateSyntheticDS.py [-h] [--alpha DATA] [--n N] [--N N]
    where alpha, n and N are, respectively, the parameter for the Zipf law, the cardinality of the stream to be generated and the number of tokens to be contained in the data stream (N >= n).
    It will output the stream generated in a file called zipf_alpha_n_N where alpha, n and N are the chosen parameters.
  - The .txt files generated with the script already described and used for the report.
  - The /output folder with the output files obtained using the script assignment3.py (i.e., running the algorithms) with the data streams generated by the Zipfian law (the ones in the zipf folder) as input. The output are grouped for each value of alpha.
- [datasets](https://github.com/luigibruzzese/UPC-RA-MIRI-Lab/blob/main/Assignment-3/datasets) is the folder that contains the datasets provided and another folder, named output, with the outputs generated for all of them by the script auto.py (i.e., by the run of all the analyzed combinations of algorithm-parameter of assignment3.py).

Notice that the version that has been used is python3.11. Different versions can require further installations of libraries (such as numpy, random) that are used in the script to achieve the provided results.
